{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python standard library imports\n",
    "from typing import Self, Any\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building imports\n",
    "from keras import Model, Sequential, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from keras.ops import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training imports\n",
    "from keras.optimizers import SGD\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.metrics import CategoricalAccuracy, AUC, F1Score\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation operations\n",
    "from keras.layers import RandomBrightness, RandomFlip, RandomRotation\n",
    "from keras.layers import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom modules imports\n",
    "from src.utils import load_cifar10_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10\n",
    "\n",
    "# specify input_shape and number of classes\n",
    "input_shape = (32, 32, 3) # RGB\n",
    "n_classes = 10\n",
    "\n",
    "# 0. airplane\n",
    "# 1. car\n",
    "# 2. bird\n",
    "# 3. cat\n",
    "# 4. deer\n",
    "# 5. dog\n",
    "# 6. frog\n",
    "# 7. horse\n",
    "# 8. ship\n",
    "# 9. truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_range = (0.0, 1.0)\n",
    "\n",
    "augmentation_layer = Pipeline(\n",
    "    [\n",
    "        RandomBrightness(factor=0.1, value_range=value_range),\n",
    "        RandomFlip(),\n",
    "        RandomRotation(factor=0.1, fill_mode=\"reflect\")\n",
    "    ],\n",
    "    name=\"augmentation_layer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTinyCNN(Model):\n",
    "    \"\"\"\n",
    "    MyTinyCNN class, inherets from keras' Model class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self: Self, activation: str = \"relu\") -> None:\n",
    "        \"\"\"\n",
    "        Initialization\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(name=\"my_tiny_oo_cnn\")\n",
    "\n",
    "        self.augmentation_layer = augmentation_layer\n",
    "\n",
    "        self.conv_layer_1 = Conv2D(\n",
    "            filters=3 * 8,\n",
    "            kernel_size=(3, 3),\n",
    "            activation=activation,\n",
    "            name=\"conv_layer_1\"\n",
    "        )\n",
    "        self.max_pool_layer_1 = MaxPooling2D(\n",
    "            pool_size=(2, 2),\n",
    "            name=\"max_pool_layer_1\"\n",
    "        )\n",
    "\n",
    "        # exemplify non-sequential nature of computation possible with\n",
    "        # the functional and object-oriented methods\n",
    "        self.conv_layer_2l = Conv2D(\n",
    "            filters=3 * 16,\n",
    "            kernel_size=(3, 3),\n",
    "            activation=activation,\n",
    "            name=\"conv_layer_2l\",\n",
    "            padding=\"same\"\n",
    "        )\n",
    "        self.conv_layer_2r = Conv2D(\n",
    "            filters=3 * 16,\n",
    "            kernel_size=(2, 2),\n",
    "            activation=activation,\n",
    "            name=\"conv_layer_2r\",\n",
    "            padding=\"same\"\n",
    "        )\n",
    "        self.max_pool_layer_2 = MaxPooling2D(\n",
    "            pool_size=(2, 2),\n",
    "            name=\"max_pool_layer_2\"\n",
    "        )\n",
    "\n",
    "        self.flatten_layer = Flatten(name=\"flatten_layer\")\n",
    "        self.dropout = Dropout(rate=0.3)\n",
    "        self.dense_layer = Dense(\n",
    "            n_classes,\n",
    "            activation=\"softmax\",\n",
    "            name=\"classification_head\"\n",
    "        )\n",
    "\n",
    "    def call(self: Self, inputs: Any) -> Any:\n",
    "        \"\"\"\n",
    "        Forward call\n",
    "        \"\"\"\n",
    "\n",
    "        x = self.augmentation_layer(inputs)\n",
    "\n",
    "\n",
    "        x = self.conv_layer_1(x)\n",
    "        x = self.max_pool_layer_1(x)\n",
    "\n",
    "        # exemplify non-sequential nature of computation possible with\n",
    "        # the functional and object-oriented methods\n",
    "        x_l = self.conv_layer_2l(x)\n",
    "        x_r = self.conv_layer_2r(x)\n",
    "        x = add(x_l, x_r)\n",
    "        x = self.max_pool_layer_2(x)\n",
    "\n",
    "        x = self.flatten_layer(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return  self.dense_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our regularized MyTinyCNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_cifar10_sample(1024, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 32\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add L2 weight decay to the optimizer directly, don't add a new loss term\n",
    "model = MyTinyCNN()\n",
    "optimizer = SGD(learning_rate=0.01, name=\"optimizer\", weight_decay=0.01)\n",
    "loss = CategoricalCrossentropy(name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "categorical_accuracy = CategoricalAccuracy(name=\"accuracy\")\n",
    "auc = AUC(name=\"auc\")\n",
    "f1_score = F1Score(average=\"macro\", name=\"f1_score\")\n",
    "metrics = [categorical_accuracy, auc, f1_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traces the computation\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are callbacks?\n",
    "root_dir_path = Path(\".\")\n",
    "checkpoint_file_path = root_dir_path / \"checkpoint.keras\"\n",
    "metrics_file_path = root_dir_path = root_dir_path / \"metrics.csv\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    checkpoint_file_path,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0\n",
    ")\n",
    "metrics_callback = CSVLogger(metrics_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a learning rate scheduler ?\n",
    "def exp_decay_lr_scheduler(\n",
    "    epoch: int,\n",
    "    current_lr: float,\n",
    "    factor: float = 0.95\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Exponential decay learning rate scheduler\n",
    "    \"\"\"\n",
    "\n",
    "    current_lr *= factor\n",
    "\n",
    "    return current_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler_callback = LearningRateScheduler(exp_decay_lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    checkpoint_callback,\n",
    "    metrics_callback,\n",
    "    lr_scheduler_callback\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "52/52 - 1s - 18ms/step - accuracy: 0.1111 - auc: 0.5205 - f1_score: 0.0768 - loss: 2.3106 - val_accuracy: 0.1317 - val_auc: 0.5223 - val_f1_score: 0.0818 - val_loss: 2.3034 - learning_rate: 0.0095\n",
      "Epoch 2/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.1392 - auc: 0.5492 - f1_score: 0.0855 - loss: 2.2909 - val_accuracy: 0.1220 - val_auc: 0.5476 - val_f1_score: 0.0791 - val_loss: 2.2923 - learning_rate: 0.0090\n",
      "Epoch 3/32\n",
      "52/52 - 0s - 5ms/step - accuracy: 0.1392 - auc: 0.5675 - f1_score: 0.0821 - loss: 2.2818 - val_accuracy: 0.1171 - val_auc: 0.5484 - val_f1_score: 0.0703 - val_loss: 2.2862 - learning_rate: 0.0086\n",
      "Epoch 4/32\n",
      "52/52 - 0s - 5ms/step - accuracy: 0.1258 - auc: 0.5868 - f1_score: 0.0789 - loss: 2.2717 - val_accuracy: 0.1220 - val_auc: 0.5714 - val_f1_score: 0.0545 - val_loss: 2.2787 - learning_rate: 0.0081\n",
      "Epoch 5/32\n",
      "52/52 - 0s - 5ms/step - accuracy: 0.1502 - auc: 0.6080 - f1_score: 0.0890 - loss: 2.2553 - val_accuracy: 0.0976 - val_auc: 0.5822 - val_f1_score: 0.0680 - val_loss: 2.2677 - learning_rate: 0.0077\n",
      "Epoch 6/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.1538 - auc: 0.6238 - f1_score: 0.1017 - loss: 2.2391 - val_accuracy: 0.1512 - val_auc: 0.6166 - val_f1_score: 0.1118 - val_loss: 2.2351 - learning_rate: 0.0074\n",
      "Epoch 7/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.2100 - auc: 0.6373 - f1_score: 0.1590 - loss: 2.2179 - val_accuracy: 0.2000 - val_auc: 0.6600 - val_f1_score: 0.1474 - val_loss: 2.2000 - learning_rate: 0.0070\n",
      "Epoch 8/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.1648 - auc: 0.6411 - f1_score: 0.1333 - loss: 2.2097 - val_accuracy: 0.1610 - val_auc: 0.6624 - val_f1_score: 0.1350 - val_loss: 2.1958 - learning_rate: 0.0066\n",
      "Epoch 9/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.1819 - auc: 0.6498 - f1_score: 0.1372 - loss: 2.1948 - val_accuracy: 0.1854 - val_auc: 0.6555 - val_f1_score: 0.1361 - val_loss: 2.1744 - learning_rate: 0.0063\n",
      "Epoch 10/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.1917 - auc: 0.6576 - f1_score: 0.1536 - loss: 2.1750 - val_accuracy: 0.1415 - val_auc: 0.6229 - val_f1_score: 0.0888 - val_loss: 2.2111 - learning_rate: 0.0060\n",
      "Epoch 11/32\n",
      "52/52 - 0s - 5ms/step - accuracy: 0.1978 - auc: 0.6711 - f1_score: 0.1596 - loss: 2.1503 - val_accuracy: 0.2049 - val_auc: 0.6575 - val_f1_score: 0.1305 - val_loss: 2.1759 - learning_rate: 0.0057\n",
      "Epoch 12/32\n",
      "52/52 - 0s - 5ms/step - accuracy: 0.1941 - auc: 0.6653 - f1_score: 0.1554 - loss: 2.1611 - val_accuracy: 0.2390 - val_auc: 0.6719 - val_f1_score: 0.1751 - val_loss: 2.1415 - learning_rate: 0.0054\n",
      "Epoch 13/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.2100 - auc: 0.6830 - f1_score: 0.1742 - loss: 2.1324 - val_accuracy: 0.2195 - val_auc: 0.7001 - val_f1_score: 0.1577 - val_loss: 2.1056 - learning_rate: 0.0051\n",
      "Epoch 14/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.2100 - auc: 0.6906 - f1_score: 0.1745 - loss: 2.1239 - val_accuracy: 0.1951 - val_auc: 0.6613 - val_f1_score: 0.1723 - val_loss: 2.1519 - learning_rate: 0.0049\n",
      "Epoch 15/32\n",
      "52/52 - 0s - 5ms/step - accuracy: 0.2076 - auc: 0.6864 - f1_score: 0.1836 - loss: 2.1261 - val_accuracy: 0.2341 - val_auc: 0.6831 - val_f1_score: 0.1804 - val_loss: 2.1203 - learning_rate: 0.0046\n",
      "Epoch 16/32\n",
      "52/52 - 0s - 5ms/step - accuracy: 0.1929 - auc: 0.6815 - f1_score: 0.1701 - loss: 2.1251 - val_accuracy: 0.1659 - val_auc: 0.6595 - val_f1_score: 0.1187 - val_loss: 2.1416 - learning_rate: 0.0044\n",
      "Epoch 17/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.2173 - auc: 0.6919 - f1_score: 0.1925 - loss: 2.1104 - val_accuracy: 0.1707 - val_auc: 0.6418 - val_f1_score: 0.1257 - val_loss: 2.1802 - learning_rate: 0.0042\n",
      "Epoch 18/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.2247 - auc: 0.6910 - f1_score: 0.1903 - loss: 2.1131 - val_accuracy: 0.2000 - val_auc: 0.6749 - val_f1_score: 0.1452 - val_loss: 2.1231 - learning_rate: 0.0040\n",
      "Epoch 19/32\n",
      "52/52 - 0s - 7ms/step - accuracy: 0.2259 - auc: 0.6896 - f1_score: 0.2040 - loss: 2.1111 - val_accuracy: 0.2244 - val_auc: 0.6830 - val_f1_score: 0.1863 - val_loss: 2.1172 - learning_rate: 0.0038\n",
      "Epoch 20/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.2112 - auc: 0.6913 - f1_score: 0.1802 - loss: 2.1132 - val_accuracy: 0.1902 - val_auc: 0.7008 - val_f1_score: 0.1528 - val_loss: 2.0748 - learning_rate: 0.0036\n",
      "Epoch 21/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.2381 - auc: 0.6948 - f1_score: 0.2120 - loss: 2.1034 - val_accuracy: 0.2146 - val_auc: 0.6955 - val_f1_score: 0.1794 - val_loss: 2.0909 - learning_rate: 0.0034\n",
      "Epoch 22/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.2369 - auc: 0.7024 - f1_score: 0.2093 - loss: 2.0903 - val_accuracy: 0.2146 - val_auc: 0.6971 - val_f1_score: 0.1807 - val_loss: 2.0933 - learning_rate: 0.0032\n",
      "Epoch 23/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.2430 - auc: 0.6975 - f1_score: 0.2189 - loss: 2.0967 - val_accuracy: 0.2098 - val_auc: 0.6967 - val_f1_score: 0.1667 - val_loss: 2.0907 - learning_rate: 0.0031\n",
      "Epoch 24/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.2454 - auc: 0.7122 - f1_score: 0.2144 - loss: 2.0796 - val_accuracy: 0.2244 - val_auc: 0.6988 - val_f1_score: 0.1948 - val_loss: 2.0896 - learning_rate: 0.0029\n",
      "Epoch 25/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.2430 - auc: 0.7022 - f1_score: 0.2097 - loss: 2.0915 - val_accuracy: 0.1902 - val_auc: 0.7065 - val_f1_score: 0.1481 - val_loss: 2.0780 - learning_rate: 0.0028\n",
      "Epoch 26/32\n",
      "52/52 - 0s - 5ms/step - accuracy: 0.2308 - auc: 0.7082 - f1_score: 0.2052 - loss: 2.0795 - val_accuracy: 0.1951 - val_auc: 0.6902 - val_f1_score: 0.1586 - val_loss: 2.1006 - learning_rate: 0.0026\n",
      "Epoch 27/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.2454 - auc: 0.7113 - f1_score: 0.2267 - loss: 2.0820 - val_accuracy: 0.2146 - val_auc: 0.6858 - val_f1_score: 0.1806 - val_loss: 2.1129 - learning_rate: 0.0025\n",
      "Epoch 28/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.2442 - auc: 0.7093 - f1_score: 0.2129 - loss: 2.0754 - val_accuracy: 0.2439 - val_auc: 0.7110 - val_f1_score: 0.2044 - val_loss: 2.0653 - learning_rate: 0.0024\n",
      "Epoch 29/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.2430 - auc: 0.7115 - f1_score: 0.2126 - loss: 2.0757 - val_accuracy: 0.2293 - val_auc: 0.6904 - val_f1_score: 0.1863 - val_loss: 2.0964 - learning_rate: 0.0023\n",
      "Epoch 30/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.2491 - auc: 0.7083 - f1_score: 0.2283 - loss: 2.0809 - val_accuracy: 0.2293 - val_auc: 0.6870 - val_f1_score: 0.2122 - val_loss: 2.1099 - learning_rate: 0.0021\n",
      "Epoch 31/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.2430 - auc: 0.7124 - f1_score: 0.2206 - loss: 2.0719 - val_accuracy: 0.2488 - val_auc: 0.7050 - val_f1_score: 0.2133 - val_loss: 2.0741 - learning_rate: 0.0020\n",
      "Epoch 32/32\n",
      "52/52 - 0s - 6ms/step - accuracy: 0.2589 - auc: 0.7174 - f1_score: 0.2392 - loss: 2.0658 - val_accuracy: 0.1902 - val_auc: 0.6998 - val_f1_score: 0.1425 - val_loss: 2.0881 - learning_rate: 0.0019\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "_ = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.203125,\n",
       " 'auc': 0.7194247841835022,\n",
       " 'f1_score': 0.16481611132621765,\n",
       " 'loss': 2.089552879333496}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate on the test set\n",
    "model.evaluate(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    batch_size=batch_size,\n",
    "    return_dict=True,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is label smoothing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next class:\n",
    "# Real data, real models, real world"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
